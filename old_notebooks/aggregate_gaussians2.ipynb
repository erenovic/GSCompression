{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load, load_inline, is_ninja_available\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "os.environ['TORCH_USE_CUDA_DSA']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(is_ninja_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = r'''\n",
    "#include <torch/types.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#include <vector_types.h>\n",
    "#include <device_launch_parameters.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "\n",
    "__global__ void update_means_opacity_sh(\n",
    "    float* weights, \n",
    "    float* mu, \n",
    "    float* opacity,\n",
    "    float* sh,\n",
    "    int* node_ids, \n",
    "    float* new_mu,\n",
    "    float* new_node_total_weight,\n",
    "    float* new_opacity,\n",
    "    float* new_sh,\n",
    "    int num_gaussians,\n",
    "    int num_sh_coeffs\n",
    ") {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= num_gaussians) return;\n",
    "\n",
    "    int node_id = node_ids[idx];\n",
    "    float weight = weights[idx];\n",
    "\n",
    "    // Weighted mu for current Gaussian\n",
    "    float mu_x = mu[idx * 3 + 0];\n",
    "    float mu_y = mu[idx * 3 + 1];\n",
    "    float mu_z = mu[idx * 3 + 2];\n",
    "\n",
    "    atomicAdd(&new_mu[node_id * 3 + 0], weight * mu_x);\n",
    "    atomicAdd(&new_mu[node_id * 3 + 1], weight * mu_y);\n",
    "    atomicAdd(&new_mu[node_id * 3 + 2], weight * mu_z);\n",
    "\n",
    "    // Weighted total weight for current node\n",
    "    atomicAdd(&new_node_total_weight[node_id], weight);\n",
    "\n",
    "    // Weighted opacity for current Gaussian\n",
    "    float op = opacity[idx];\n",
    "    atomicAdd(&new_opacity[node_id], weight * op);\n",
    "\n",
    "    // Weighted shs for current Gaussian\n",
    "    for (int k = 0; k < num_sh_coeffs; k++) {\n",
    "        atomicAdd(\n",
    "            &new_sh[node_id * num_sh_coeffs + k], \n",
    "            weight * sh[idx * num_sh_coeffs + k]\n",
    "        );\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void divide_by_total_weight(\n",
    "    float* new_mu,\n",
    "    float* new_node_total_weight,\n",
    "    float* new_opacity,\n",
    "    float* new_sh,\n",
    "    int num_new_nodes,\n",
    "    int num_sh_coeffs\n",
    ") {\n",
    "    int node_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (node_id >= num_new_nodes) return;\n",
    "\n",
    "    float total_weight = new_node_total_weight[node_id];\n",
    "\n",
    "    new_mu[node_id * 3 + 0] /= total_weight;\n",
    "    new_mu[node_id * 3 + 1] /= total_weight;\n",
    "    new_mu[node_id * 3 + 2] /= total_weight;\n",
    "\n",
    "    new_opacity[node_id] /= total_weight;\n",
    "\n",
    "    for (int k = 0; k < num_sh_coeffs; k++) {\n",
    "        new_sh[node_id * num_sh_coeffs + k] /= total_weight;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void update_covariances(\n",
    "    float* weights, \n",
    "    float* mu, \n",
    "    float* sigma, \n",
    "    int* node_ids, \n",
    "    float* new_mu, \n",
    "    float* new_sigma,\n",
    "    int num_gaussians\n",
    ") {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= num_gaussians) return;\n",
    "\n",
    "    int node_id = node_ids[idx];\n",
    "    float weight = weights[idx];\n",
    "\n",
    "    // Current mu and new_mu values\n",
    "    float mu_x = mu[idx * 3 + 0];\n",
    "    float mu_y = mu[idx * 3 + 1];\n",
    "    float mu_z = mu[idx * 3 + 2];\n",
    "\n",
    "    float new_mu_x = new_mu[node_id * 3 + 0];\n",
    "    float new_mu_y = new_mu[node_id * 3 + 1];\n",
    "    float new_mu_z = new_mu[node_id * 3 + 2];\n",
    "\n",
    "    // Difference mu_i - new_mu\n",
    "    float diff_x = mu_x - new_mu_x;\n",
    "    float diff_y = mu_y - new_mu_y;\n",
    "    float diff_z = mu_z - new_mu_z;\n",
    "\n",
    "    // Sigma indices\n",
    "    int sigma_base_idx = idx * 6;\n",
    "    int new_sigma_base_idx = node_id * 6;\n",
    "\n",
    "    // Update covariance matrix components\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 0], weight * (sigma[sigma_base_idx + 0] + diff_x * diff_x)); // sxx\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 1], weight * (sigma[sigma_base_idx + 1] + diff_x * diff_y)); // sxy\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 2], weight * (sigma[sigma_base_idx + 2] + diff_x * diff_z)); // sxz\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 3], weight * (sigma[sigma_base_idx + 3] + diff_y * diff_y)); // syy\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 4], weight * (sigma[sigma_base_idx + 4] + diff_y * diff_z)); // syz\n",
    "    atomicAdd(&new_sigma[new_sigma_base_idx + 5], weight * (sigma[sigma_base_idx + 5] + diff_z * diff_z)); // szz\n",
    "}\n",
    "\n",
    "__global__ void divide_sigma_by_total_weight(\n",
    "    float* new_node_total_weight,\n",
    "    float* new_sigma,\n",
    "    int num_new_nodes\n",
    ") {\n",
    "    int node_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (node_id >= num_new_nodes) return;\n",
    "\n",
    "    float total_weight = new_node_total_weight[node_id];\n",
    "\n",
    "    int sigma_base_idx = node_id * 6;\n",
    "\n",
    "    new_sigma[sigma_base_idx + 0] /= total_weight;\n",
    "    new_sigma[sigma_base_idx + 1] /= total_weight;\n",
    "    new_sigma[sigma_base_idx + 2] /= total_weight;\n",
    "    new_sigma[sigma_base_idx + 3] /= total_weight;\n",
    "    new_sigma[sigma_base_idx + 4] /= total_weight;\n",
    "    new_sigma[sigma_base_idx + 5] /= total_weight;\n",
    "}\n",
    "\n",
    "// Host function to launch kernels\n",
    "// Returns a tuple of tensors containing the updated means, opacities, spherical harmonics, and covariances\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians(\n",
    "    torch::Tensor weights, \n",
    "    torch::Tensor mu, \n",
    "    torch::Tensor opacity,\n",
    "    torch::Tensor sh,\n",
    "    torch::Tensor sigma, \n",
    "    torch::Tensor node_ids, \n",
    "    int num_gaussians,\n",
    "    int num_new_nodes\n",
    ") {\n",
    "\n",
    "    // Assuming mu, sigma, and opacity have the same first dimension size as num_nodes\n",
    "    // and sh has a second dimension for spherical harmonics coefficients.\n",
    "    auto options = torch::TensorOptions().dtype(weights.dtype()).device(weights.device());\n",
    "\n",
    "    int num_sh_coeffs = sh.size(1);\n",
    "\n",
    "    // Initialize new tensors inside the function\n",
    "    torch::Tensor new_mu = torch::zeros({num_new_nodes, mu.size(1)}, options);\n",
    "    torch::Tensor new_node_total_weight = torch::zeros({num_new_nodes}, options);\n",
    "    torch::Tensor new_opacity = torch::zeros({num_new_nodes}, options);\n",
    "    torch::Tensor new_sh = torch::zeros({num_new_nodes, num_sh_coeffs}, options);\n",
    "    torch::Tensor new_sigma = torch::zeros({num_new_nodes, sigma.size(1)}, options);\n",
    "\n",
    "    // Kernel configurations\n",
    "    dim3 blockSize(256);\n",
    "\n",
    "    // Launch kernel to update means\n",
    "    update_means_opacity_sh<<<((num_gaussians + blockSize.x - 1) / blockSize.x), blockSize>>>(\n",
    "        weights.data_ptr<float>(), \n",
    "        mu.data_ptr<float>(), \n",
    "        opacity.data_ptr<float>(),\n",
    "        sh.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(), \n",
    "        new_mu.data_ptr<float>(),\n",
    "        new_node_total_weight.data_ptr<float>(),\n",
    "        new_opacity.data_ptr<float>(),\n",
    "        new_sh.data_ptr<float>(),\n",
    "        num_gaussians,\n",
    "        num_sh_coeffs\n",
    "    );\n",
    "\n",
    "    // Ensure all updates to new_mu are complete\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Divide by the total weight to normalize the weights\n",
    "    divide_by_total_weight<<<((num_gaussians + blockSize.x - 1) / blockSize.x), blockSize>>>(\n",
    "        new_mu.data_ptr<float>(), \n",
    "        new_node_total_weight.data_ptr<float>(), \n",
    "        new_opacity.data_ptr<float>(),\n",
    "        new_sh.data_ptr<float>(),\n",
    "        num_new_nodes,\n",
    "        num_sh_coeffs\n",
    "    );\n",
    "\n",
    "    // Ensure all updates to new_mu are complete\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Launch kernel to update covariances\n",
    "    update_covariances<<<((num_gaussians + blockSize.x - 1) / blockSize.x), blockSize>>>(\n",
    "        weights.data_ptr<float>(), \n",
    "        mu.data_ptr<float>(), \n",
    "        sigma.data_ptr<float>(), \n",
    "        node_ids.data_ptr<int>(), \n",
    "        new_mu.data_ptr<float>(), \n",
    "        new_sigma.data_ptr<float>(),\n",
    "        num_gaussians\n",
    "    );\n",
    "\n",
    "    // Ensure all updates to new_sigma are complete\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // Divide the covariance by total weight to normalize the weights\n",
    "    divide_sigma_by_total_weight<<<((num_gaussians + blockSize.x - 1) / blockSize.x), blockSize>>>(\n",
    "        new_node_total_weight.data_ptr<float>(), \n",
    "        new_sigma.data_ptr<float>(),\n",
    "        num_new_nodes\n",
    "    );\n",
    "\n",
    "    return std::make_tuple(new_mu, new_sigma, new_opacity, new_sh);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_src = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <cstdio>\n",
    "#include <tuple>\n",
    "#include <string>\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians(\n",
    "    torch::Tensor weights, \n",
    "    torch::Tensor mu, \n",
    "    torch::Tensor opacity,\n",
    "    torch::Tensor sh,\n",
    "    torch::Tensor sigma, \n",
    "    torch::Tensor node_ids, \n",
    "    int num_gaussians,\n",
    "    int num_new_nodes\n",
    ");\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_inline(\n",
    "    cuda_sources=[cuda_src], cpp_sources=[cpp_src], \n",
    "    functions=[\"aggregate_gaussians\"],\n",
    "    build_directory=\"aggregate\",\n",
    "    extra_cuda_cflags=[],\n",
    "    verbose=True, name=\"my_cuda_extension\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submodules.octree_generation.jit_setup import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import octree_generation\n",
    "\n",
    "class OctreeGenerator(torch.autograd.Function):\n",
    "    def __init__(self):\n",
    "        super(OctreeGenerator, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, points3D: torch.Tensor, max_depth: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generate an octree from a set of 3D points. The octree is axis-aligned and\n",
    "        the bounding box is computed from the points. The octree is generated with a\n",
    "        maximum depth of `max_depth`.\n",
    "        \n",
    "        Args:\n",
    "            points3D (torch.Tensor): A tensor of shape (N, 3) representing the 3D points.\n",
    "            max_depth (int): The maximum depth of the octree.\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: A tensor of shape (N, 10) representing the octant each Gaussian\n",
    "                belongs to in every level of the octree.\n",
    "            torch.Tensor: A tensor of shape (N, `max_depth`) representing the node ids \n",
    "                of the octree nodes that contain the points.\n",
    "        \"\"\"\n",
    "        aabb_min = torch.min(points3D, dim=0)[0]\n",
    "        aabb_max = torch.max(points3D, dim=0)[0]\n",
    "\n",
    "        box_d = aabb_max - aabb_min\n",
    "        box_min = aabb_min - 0.1 * box_d\n",
    "        box_max = aabb_max + 0.1 * box_d\n",
    "\n",
    "        # Returns point_level_bboxes, point_node_assignment\n",
    "        return octree_generation.generate_octree(points3D, box_min, box_max, max_depth)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_octree(points: torch.Tensor, max_depth: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    return OctreeGenerator.apply(points, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.build_config_spaces import ConfigReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ConfigReader(\"config/preset_configs/hierarchical_gaussian.yaml\")\n",
    "dataset = reader.dataset_config\n",
    "pipeline = reader.pipeline_config\n",
    "optimization = reader.optimization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.splatting.base_gaussian_model import BaseGaussianModel\n",
    "from training.base_gaussian_trainer import BaseGaussianTrainer\n",
    "from utils.general_utils import build_scales_and_quaternions_from_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data_path = dataset.data_path + \"/tandt/train\"\n",
    "print(dataset.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians = BaseGaussianModel(dataset=dataset)\n",
    "trainer = BaseGaussianTrainer(\n",
    "    dataset, optimization, pipeline, gaussians, logger=None, \n",
    "    checkpoint=None\n",
    ")\n",
    "trainer.restore(\"output/base/train/checkpoints/ckpt_30000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unique_values(data):\n",
    "    # data should be a CUDA tensor of shape (N, 10)\n",
    "    new_data = data.clone()\n",
    "    N, C = data.shape\n",
    "    for i in range(C):\n",
    "        unique_values, new_indices = torch.unique(data[:, i], sorted=True, return_inverse=True)\n",
    "        new_data[:, i] = new_indices  # Replace column with new indices\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def calculate_weights(scales, opacity):\n",
    "    radii = 3 * scales\n",
    "    p = 1.6075\n",
    "    a, b, c = radii.chunk(3, dim=1)\n",
    "    # 4 * torch.pi * ((a**p * b**p + a**p * c**p + b**p * c**p) / 3)**(1/p)\n",
    "    weights = (\n",
    "        opacity * ((a**p * b**p + a**p * c**p + b**p * c**p)**(1/p))\n",
    "    )\n",
    "    return weights\n",
    "\n",
    "def recursive_aggregation(\n",
    "    weights: torch.Tensor, \n",
    "    mu: torch.Tensor, \n",
    "    opacity: torch.Tensor, \n",
    "    sh: torch.Tensor, \n",
    "    sigma: torch.Tensor, \n",
    "    node_ids: torch.Tensor, \n",
    "    min_level: int, \n",
    "    max_level: int,\n",
    "    return_all_levels: bool = False\n",
    "):\n",
    "\n",
    "    assert min_level <= max_level, \"Minimum level should be less than or equal to maximum level\"\n",
    "\n",
    "    current_mu = mu\n",
    "    current_opacity = opacity\n",
    "    current_sh = sh\n",
    "    current_sigma = sigma\n",
    "    current_weights = weights\n",
    "    \n",
    "    # Current mapping between Gaussians and lowest level nodes\n",
    "    # current_node_ids = node_ids[:, max_level - 1]\n",
    "    sorted_node_ids = node_ids\n",
    "\n",
    "    if return_all_levels:\n",
    "        new_gaussian_mus = torch.empty(0, 3).cuda()\n",
    "        new_gaussian_scales = torch.empty(0, 3).cuda()\n",
    "        new_gaussian_rotations = torch.empty(0, 4).cuda()\n",
    "        new_gaussian_opacities = torch.empty(0, 1).cuda()\n",
    "        new_gaussian_shs = torch.empty(0, sh.size(1)).cuda()\n",
    "\n",
    "    for level in range(max_level - 1, min_level-1, -1):\n",
    "        # Map node ids to dense structure instead of sparse one\n",
    "        new_node_ids_assigned = sorted_node_ids[:, level].type(torch.int32)\n",
    "        num_nodes_at_level = new_node_ids_assigned.max() + 1\n",
    "\n",
    "        # Call a CUDA function to perform aggregation\n",
    "        new_mu, new_sigma, new_opacity, new_sh, new_total_weights = module.aggregate_gaussians(\n",
    "            current_weights,\n",
    "            current_mu,\n",
    "            current_opacity,\n",
    "            current_sh,\n",
    "            current_sigma,\n",
    "            new_node_ids_assigned.cuda(),\n",
    "            current_mu.shape[0],\n",
    "            num_nodes_at_level\n",
    "        )\n",
    "\n",
    "        # Debugging: Check if the means are correct\n",
    "        # uniques, counts = torch.unique(new_node_ids_assigned, return_counts=True)\n",
    "        # mask = new_node_ids_assigned == uniques[torch.argmax(counts)]\n",
    "        # print(current_mu[mask].shape)\n",
    "        # print(current_weights[mask].shape)\n",
    "        # print((current_mu[mask] * current_weights[mask]).sum(dim=0) / current_weights[mask].sum())\n",
    "        # print(new_mu[uniques[torch.argmax(counts)]])\n",
    "\n",
    "        current_mu = new_mu\n",
    "        current_sigma = new_sigma\n",
    "        current_opacity = new_opacity\n",
    "        current_sh = new_sh\n",
    "\n",
    "        current_scales, current_rotations = build_scales_and_quaternions_from_cov(current_sigma)\n",
    "\n",
    "        # Append new mu and sigma\n",
    "        if return_all_levels:\n",
    "            new_gaussian_mus = torch.cat(\n",
    "                (new_gaussian_mus, current_mu), dim=0)\n",
    "            new_gaussian_scales = torch.cat(\n",
    "                (new_gaussian_scales, current_scales), dim=0)\n",
    "            new_gaussian_rotations = torch.cat(\n",
    "                (new_gaussian_rotations, current_rotations), dim=0)\n",
    "            new_gaussian_opacities = torch.cat(\n",
    "                (new_gaussian_opacities, current_opacity[:, None]), dim=0)\n",
    "            new_gaussian_shs = torch.cat(\n",
    "                (new_gaussian_shs, current_sh), dim=0)\n",
    "\n",
    "        current_weights = calculate_weights(current_scales, current_opacity[:, None])\n",
    "\n",
    "        sorted_node_ids = sorted_node_ids[new_node_ids_assigned.sort()[1]]\n",
    "\n",
    "        # Find where the value changes in the specified column\n",
    "        unique_indices = torch.cat((torch.tensor([True]).cuda(), sorted_node_ids[1:, -1] != sorted_node_ids[:-1, -1]))\n",
    "        sorted_node_ids = sorted_node_ids[unique_indices, :-1]\n",
    "\n",
    "    if return_all_levels:\n",
    "        return new_gaussian_mus, new_gaussian_scales, new_gaussian_rotations, new_gaussian_opacities, new_gaussian_shs\n",
    "    else:\n",
    "        return current_mu, current_scales, current_rotations, current_opacity, current_sh\n",
    "\n",
    "# Example usage\n",
    "octree_max_depth = 15\n",
    "octree_min_depth = 5\n",
    "mu = gaussians._xyz.data\n",
    "sigma = gaussians.get_covariance()\n",
    "opacity = gaussians.get_opacity\n",
    "sh = gaussians.get_features\n",
    "num_sh_coeffs = sh.size(1)\n",
    "\n",
    "scales, quaternions = build_scales_and_quaternions_from_cov(sigma)\n",
    "\n",
    "weights = calculate_weights(gaussians.get_scaling, opacity)\n",
    "\n",
    "# 3-sigma Gaussian ellipsoid surface approximation\n",
    "_, gaussian_node_assignments = generate_octree(\n",
    "    points=gaussians._xyz, max_depth=octree_max_depth\n",
    ")\n",
    "\n",
    "# Node ids were unique for the overall tensor, now we make them unique per depth level\n",
    "# gaussian_node_assignments = assign_unique_values(gaussian_node_assignments)\n",
    "unique_per_col_gaussian_node_assignments = assign_unique_values(gaussian_node_assignments)\n",
    "\n",
    "final_mu, final_scale, final_rotation, final_opacity, final_sh = recursive_aggregation(\n",
    "    weights, mu, opacity, sh, sigma, unique_per_col_gaussian_node_assignments, \n",
    "    octree_min_depth, octree_max_depth, return_all_levels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_mu.min(), final_mu.max())\n",
    "print(final_scale.min(), final_scale.max())\n",
    "print(final_rotation.min(), final_rotation.max())\n",
    "print(final_opacity.min(), final_opacity.max())\n",
    "print(final_sh.min(), final_sh.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data in PyTorch tensor\n",
    "points = final_mu[::10].detach().cpu()\n",
    "print(points.shape[0])\n",
    "\n",
    "# Convert PyTorch tensor to NumPy arrays\n",
    "x = points[:, 0].numpy()\n",
    "y = points[:, 1].numpy()\n",
    "z = points[:, 2].numpy()\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color=z,  # color points by Z value\n",
    "        colorscale='Viridis',  # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title='3D Point Cloud',\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis',\n",
    "        camera=dict(\n",
    "            eye=dict(x=1, y=1, z=0.5),  # Adjust x, y, z to change the viewpoint\n",
    "            up=dict(x=0, y=0, z=1),     # Keeping the z-axis pointing up\n",
    "            center=dict(x=0, y=0, z=0)  # Camera is looking at the origin\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data in PyTorch tensor\n",
    "points = gaussians._xyz[::2].detach().cpu()\n",
    "print(points.shape[0])\n",
    "\n",
    "# Convert PyTorch tensor to NumPy arrays\n",
    "x = points[:, 0].numpy()\n",
    "y = points[:, 1].numpy()\n",
    "z = points[:, 2].numpy()\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color=z,  # color points by Z value\n",
    "        colorscale='Viridis',  # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title='3D Point Cloud',\n",
    "    scene=dict(\n",
    "        xaxis_title='X Axis',\n",
    "        yaxis_title='Y Axis',\n",
    "        zaxis_title='Z Axis',\n",
    "        camera=dict(\n",
    "            eye=dict(x=1, y=1, z=0.5),  # Adjust x, y, z to change the viewpoint\n",
    "            up=dict(x=0, y=0, z=1),     # Keeping the z-axis pointing up\n",
    "            center=dict(x=0, y=0, z=0)  # Camera is looking at the origin\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin_scratch/GSCodec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ecetin/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module octree_generation, skipping build step...\n",
      "Loading extension module octree_generation...\n",
      "Using /home/ecetin/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module gaussian_aggregation, skipping build step...\n",
      "Loading extension module gaussian_aggregation...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from submodules.gaussian_aggregation.jit_setup import setup as setup_gaussian_aggregation\n",
    "from submodules.octree_generation.jit_setup import setup as setup_octree_generation\n",
    "\n",
    "setup_octree_generation()\n",
    "setup_gaussian_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gaussian_aggregation\n",
    "\n",
    "class AggregationFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, weights, xyzs, opacities, shs, sigmas, node_ids):\n",
    "        num_gaussians = xyzs.shape[0]\n",
    "        num_nodes_at_level = node_ids.max() + 1\n",
    "\n",
    "        new_xyzs, new_sigmas, new_opacities, new_shs, new_node_total_weights = (\n",
    "            gaussian_aggregation.aggregate_gaussians_forward(\n",
    "                weights, xyzs, opacities, shs, sigmas, node_ids, num_gaussians, num_nodes_at_level\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Store for backward\n",
    "        ctx.save_for_backward(\n",
    "            weights, xyzs, new_xyzs, opacities, shs, sigmas, node_ids, new_node_total_weights\n",
    "        )\n",
    "        ctx.num_gaussians = num_gaussians\n",
    "        ctx.num_nodes_at_level = num_nodes_at_level\n",
    "\n",
    "        return new_xyzs, new_sigmas, new_opacities, new_shs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_new_xyzs, grad_new_sigmas, grad_new_opacities, grad_new_shs):\n",
    "        # Gradient calculations\n",
    "\n",
    "        # Retrieve saved tensors\n",
    "        (weights, mu, new_mu, opacity, sh, sigma, node_ids, node_total_weights) = ctx.saved_tensors\n",
    "\n",
    "        num_gaussians = ctx.num_gaussians\n",
    "        num_nodes_at_level = ctx.num_nodes_at_level\n",
    "\n",
    "        # Calculate gradients for inputs based on grad_outputs\n",
    "        grad_weights, grad_mu, grad_opacity, grad_sh, grad_sigma = (\n",
    "            gaussian_aggregation.aggregate_gaussians_backward(\n",
    "                grad_new_xyzs,\n",
    "                grad_new_sigmas,\n",
    "                grad_new_opacities,\n",
    "                grad_new_shs,\n",
    "                node_total_weights,\n",
    "                weights,\n",
    "                mu,\n",
    "                new_mu,\n",
    "                opacity,\n",
    "                sh,\n",
    "                sigma,\n",
    "                node_ids,\n",
    "                num_gaussians,\n",
    "                num_nodes_at_level,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return grad_weights, grad_mu, grad_opacity, grad_sh, grad_sigma, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import octree_generation\n",
    "\n",
    "class OctreeGenerator(torch.autograd.Function):\n",
    "    def __init__(self):\n",
    "        super(OctreeGenerator, self).__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, points3D: torch.Tensor, max_depth: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Generate an octree from a set of 3D points. The octree is axis-aligned and\n",
    "        the bounding box is computed from the points. The octree is generated with a\n",
    "        maximum depth of `max_depth`.\n",
    "\n",
    "        Args:\n",
    "            points3D (torch.Tensor): A tensor of shape (N, 3) representing the 3D points.\n",
    "            max_depth (int): The maximum depth of the octree.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor of shape (N, 10) representing the octant each Gaussian\n",
    "                belongs to in every level of the octree.\n",
    "            torch.Tensor: A tensor of shape (N, `max_depth`) representing the node ids\n",
    "                of the octree nodes that contain the points.\n",
    "        \"\"\"\n",
    "        aabb_min = torch.min(points3D, dim=0)[0]\n",
    "        aabb_max = torch.max(points3D, dim=0)[0]\n",
    "\n",
    "        box_d = aabb_max - aabb_min\n",
    "        box_min = aabb_min - 0.1 * box_d\n",
    "        box_max = aabb_max + 0.1 * box_d\n",
    "\n",
    "        # Returns point_level_bboxes, point_node_assignment\n",
    "        return octree_generation.generate_octree(points3D, box_min, box_max, max_depth)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def generate_octree(points: torch.Tensor, max_depth: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    return OctreeGenerator.apply(points, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general_utils import build_scales_and_quaternions_from_cov, build_covariance_from_scaling_rotation\n",
    "\n",
    "def calculate_weights(scales, opacity):\n",
    "    radii = 3 * scales\n",
    "    p = 1.6075\n",
    "    a, b, c = radii.chunk(3, dim=1)\n",
    "    # 4 * torch.pi * ((a**p * b**p + a**p * c**p + b**p * c**p) / 3)**(1/p)\n",
    "    weights = opacity * ((a**p * b**p + a**p * c**p + b**p * c**p) ** (1 / p))\n",
    "    return weights\n",
    "\n",
    "\n",
    "def assign_unique_values(data):\n",
    "    # data should be a CUDA tensor of shape (N, 10)\n",
    "    new_data = data.clone()\n",
    "    N, C = data.shape\n",
    "    for i in range(C):\n",
    "        unique_values, new_indices = torch.unique(data[:, i], sorted=True, return_inverse=True)\n",
    "        new_data[:, i] = new_indices  # Replace column with new indices\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def aggregate_gaussians_recursively(\n",
    "    weights: torch.Tensor,\n",
    "    mu: torch.Tensor,\n",
    "    opacity: torch.Tensor,\n",
    "    sh: torch.Tensor,\n",
    "    sigma: torch.Tensor,\n",
    "    node_ids: torch.Tensor,\n",
    "    min_level: int,\n",
    "    max_level: int,\n",
    "    return_all_levels: bool = False,\n",
    "):\n",
    "\n",
    "    assert min_level <= max_level, \"Minimum level should be less than or equal to maximum level\"\n",
    "\n",
    "    current_mu = mu\n",
    "    current_opacity = opacity\n",
    "    current_sh = sh\n",
    "    current_sigma = sigma\n",
    "    current_weights = weights\n",
    "    current_rotations = None\n",
    "    current_scales = None\n",
    "\n",
    "    # Current mapping between Gaussians and lowest level nodes\n",
    "    # current_node_ids = node_ids[:, max_level - 1]\n",
    "    sorted_node_ids = node_ids\n",
    "\n",
    "    if return_all_levels:\n",
    "        new_gaussian_mus = torch.empty(0, 3).cuda()\n",
    "        # new_gaussian_scales = torch.empty(0, 3).cuda()\n",
    "        # new_gaussian_rotations = torch.empty(0, 4).cuda()\n",
    "        new_gaussian_sigmas = torch.empty(0, 6).cuda()\n",
    "        new_gaussian_opacities = torch.empty(0, 1).cuda()\n",
    "        new_gaussian_shs = torch.empty(0, sh.size(1) * 3).cuda()\n",
    "\n",
    "    for level in range(max_level - 1, min_level - 1, -1):\n",
    "        # Map node ids to dense structure instead of sparse one\n",
    "        new_node_ids_assigned = sorted_node_ids[:, level].type(torch.int32)\n",
    "\n",
    "        # Call function to perform aggregation\n",
    "        new_mu, new_sigma, new_opacity, new_sh = AggregationFunction.apply(\n",
    "            current_weights,\n",
    "            current_mu,\n",
    "            current_opacity,\n",
    "            current_sh,\n",
    "            current_sigma,\n",
    "            new_node_ids_assigned,\n",
    "        )\n",
    "\n",
    "        # Debugging: Check if the means are correct\n",
    "        # uniques, counts = torch.unique(new_node_ids_assigned, return_counts=True)\n",
    "        # mask = new_node_ids_assigned == uniques[torch.argmax(counts)]\n",
    "        # print(current_mu[mask].shape)\n",
    "        # print(current_weights[mask].shape)\n",
    "        # print((current_mu[mask] * current_weights[mask]).sum(dim=0) / current_weights[mask].sum())\n",
    "        # print(new_mu[uniques[torch.argmax(counts)]])\n",
    "\n",
    "        current_mu = new_mu\n",
    "        current_sigma = new_sigma\n",
    "        current_opacity = new_opacity\n",
    "        current_sh = new_sh\n",
    "\n",
    "        # Return covariance directly:\n",
    "        current_scales, current_rotations = build_scales_and_quaternions_from_cov(current_sigma)\n",
    "\n",
    "        # Append new mu and sigma\n",
    "        if return_all_levels:\n",
    "            new_gaussian_mus = torch.cat((new_gaussian_mus, current_mu), dim=0)\n",
    "            new_gaussian_scales = torch.cat((new_gaussian_scales, current_scales), dim=0)\n",
    "            new_gaussian_rotations = torch.cat((new_gaussian_rotations, current_rotations), dim=0)\n",
    "            new_gaussian_sigmas = torch.cat((new_gaussian_sigmas, current_sigma), dim=0)\n",
    "            new_gaussian_opacities = torch.cat(\n",
    "                (new_gaussian_opacities, current_opacity[:, None]), dim=0\n",
    "            )\n",
    "            new_gaussian_shs = torch.cat((new_gaussian_shs, current_sh), dim=0)\n",
    "\n",
    "        current_weights = calculate_weights(current_scales, current_opacity[:, None])\n",
    "\n",
    "        sorted_node_ids = sorted_node_ids[new_node_ids_assigned.sort()[1]]\n",
    "\n",
    "        # Find where the value changes in the specified column\n",
    "        unique_indices = torch.cat(\n",
    "            (torch.tensor([True]).cuda(), sorted_node_ids[1:, -1] != sorted_node_ids[:-1, -1])\n",
    "        )\n",
    "        sorted_node_ids = sorted_node_ids[unique_indices, :-1]\n",
    "\n",
    "    # Returning current weights for debugging purposes\n",
    "    if return_all_levels:\n",
    "        return (\n",
    "            new_gaussian_mus,\n",
    "            new_gaussian_scales,\n",
    "            new_gaussian_rotations,\n",
    "            new_gaussian_sigmas,\n",
    "            new_gaussian_opacities,\n",
    "            new_gaussian_shs,\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            current_mu,\n",
    "            current_scales,\n",
    "            current_rotations,\n",
    "            current_sigma,\n",
    "            current_opacity,\n",
    "            current_sh,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "R = 50\n",
    "xyzs = torch.randn((N, 3)).cuda() * 50\n",
    "scales = torch.randn((N, 3)).cuda() * 20\n",
    "rotations = torch.randn((N, 4)).cuda()\n",
    "opacities = torch.sigmoid(torch.randn((N, 1)).cuda() * 10)\n",
    "shs = torch.randn((N, 16, 3)).cuda()\n",
    "sigmas = build_covariance_from_scaling_rotation(scales, 1.0, rotations)\n",
    "weights = torch.ones(N, 1).cuda()\n",
    "\n",
    "octree_max_depth = 1\n",
    "\n",
    "# 3-sigma Gaussian ellipsoid surface approximation\n",
    "_, gaussian_node_assignments = generate_octree(points=xyzs, max_depth=octree_max_depth)\n",
    "\n",
    "# Node ids were unique for the overall tensor, now we make them unique per depth level\n",
    "# gaussian_node_assignments = assign_unique_values(gaussian_node_assignments)\n",
    "unique_per_col_gaussian_node_assignments = assign_unique_values(\n",
    "    gaussian_node_assignments\n",
    ").contiguous()\n",
    "\n",
    "(\n",
    "    current_mu,\n",
    "    current_scales,\n",
    "    current_rotations,\n",
    "    current_sigma,\n",
    "    current_opacity,\n",
    "    current_sh,\n",
    ") = aggregate_gaussians_recursively(\n",
    "    weights,\n",
    "    xyzs,\n",
    "    opacities,\n",
    "    shs,\n",
    "    sigmas,\n",
    "    unique_per_col_gaussian_node_assignments,\n",
    "    0,\n",
    "    octree_max_depth,\n",
    "    return_all_levels=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1150, -0.9386, -1.2061],\n",
      "        [ 1.2101, -1.3982, -1.2553],\n",
      "        [-0.9554,  1.1580, -0.7895],\n",
      "        [ 0.6118,  0.7821, -1.0802],\n",
      "        [-0.9496, -1.0083,  0.4498],\n",
      "        [ 0.6847, -0.9190,  0.4641],\n",
      "        [-0.7937,  0.9383,  0.4655],\n",
      "        [ 0.8571,  0.4280,  0.6931]], device='cuda:0')\n",
      "tensor([[ 0.7775,  0.0474, -0.1793,  0.6820,  0.0602,  0.9855],\n",
      "        [ 1.6438,  0.5553, -0.3258,  1.4254,  0.1036,  1.6146],\n",
      "        [ 1.2818,  0.3129, -0.6469,  0.8555, -0.1525,  1.1421],\n",
      "        [ 1.6533,  0.4284, -0.3207,  1.3396, -0.0149,  1.5847],\n",
      "        [ 1.3409,  0.2237, -0.4443,  0.9981,  0.0648,  1.4182],\n",
      "        [ 1.2297,  0.2280, -0.2533,  1.1439,  0.0292,  1.2440],\n",
      "        [ 1.3946,  0.2321, -0.2262,  1.3414, -0.1972,  1.2725],\n",
      "        [ 1.3676,  0.2132, -0.4252,  0.8227, -0.0582,  1.1683]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "new_means = torch.empty(0, 3).cuda()\n",
    "\n",
    "for i in range(unique_per_col_gaussian_node_assignments.unique().shape[0]):\n",
    "\n",
    "    mean = (xyzs[(unique_per_col_gaussian_node_assignments == i)[:, 0]] * weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]]).sum(0) \\\n",
    "        / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "    \n",
    "    new_means = torch.cat((new_means, mean[None]), dim=0)\n",
    "\n",
    "new_sigmas = torch.zeros((new_means.shape[0], 6)).cuda()\n",
    "\n",
    "for i in range(unique_per_col_gaussian_node_assignments.unique().shape[0]):\n",
    "\n",
    "    diffs = (xyzs[(unique_per_col_gaussian_node_assignments == i)[:, 0]] - new_means[i])\n",
    "    diffs_x = diffs[:, 0]\n",
    "    diffs_y = diffs[:, 1]\n",
    "    diffs_z = diffs[:, 2]\n",
    "\n",
    "    sigma = torch.zeros(6).cuda()\n",
    "\n",
    "    for j in range(diffs.shape[0]):\n",
    "        sigma[0] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 0] + diffs_x[j] * diffs_x[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        sigma[1] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 1] + diffs_x[j] * diffs_y[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        sigma[2] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 2] + diffs_x[j] * diffs_z[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        sigma[3] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 3] + diffs_y[j] * diffs_y[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        sigma[4] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 4] + diffs_y[j] * diffs_z[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        sigma[5] += weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]][j, 0] * \\\n",
    "            (sigmas[j, 5] + diffs_z[j] * diffs_z[j]) / weights[(unique_per_col_gaussian_node_assignments == i)[:, 0]].sum()\n",
    "        \n",
    "    new_sigmas[i] = sigma\n",
    "\n",
    "print(new_means)\n",
    "print(new_sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8007e+00,  2.9974e-01, -8.2606e-01,  9.8344e-01, -2.6561e-01,\n",
       "          1.0607e+00],\n",
       "        [ 4.2579e-02,  1.1345e-01,  1.7128e-01,  8.6590e-01,  1.1469e+00,\n",
       "          1.5522e+00],\n",
       "        [ 1.7446e-01,  1.3222e-02,  3.2376e-02,  2.0183e-01,  7.8317e-02,\n",
       "          4.3991e-02],\n",
       "        [ 5.2014e-01, -1.0774e-01, -1.3292e-01,  3.5611e-02,  1.1307e-01,\n",
       "          8.4713e-01],\n",
       "        [ 6.2518e-01,  7.6846e-02, -1.4033e-01,  6.2591e-01, -2.2500e-01,\n",
       "          3.4635e-01],\n",
       "        [ 5.5271e-01, -6.5183e-02, -1.0296e-02,  1.8329e-01,  2.2725e-01,\n",
       "          3.8100e-01],\n",
       "        [ 4.0767e+00,  1.6006e+00, -2.8158e+00,  1.0559e+00, -1.2280e+00,\n",
       "          2.7741e+00],\n",
       "        [ 2.4729e+00,  1.3487e+00, -1.2702e+00,  8.7487e-01, -8.0113e-01,\n",
       "          9.5965e-01],\n",
       "        [ 8.3145e-03,  3.0544e-02,  4.7372e-03,  2.2030e-01,  1.0711e-01,\n",
       "          7.8924e-02],\n",
       "        [ 3.7630e+00,  1.5963e-01, -4.3913e-01,  3.1914e+00, -6.2918e-01,\n",
       "          3.0263e+00],\n",
       "        [ 1.4791e+00,  3.6491e-01,  2.2292e-01,  1.2571e+00,  2.7534e-01,\n",
       "          1.0324e+00],\n",
       "        [ 2.4536e-01, -4.2378e-02,  4.9830e-02,  2.2296e-01,  9.2238e-02,\n",
       "          2.2741e-01],\n",
       "        [ 2.9509e-01, -1.4758e-01,  1.9064e-01,  3.6356e-01, -2.3798e-02,\n",
       "          2.3066e-01],\n",
       "        [ 3.7582e-01, -2.1037e-01, -3.6228e-02,  2.9462e-01,  2.2263e-01,\n",
       "          2.5132e-01],\n",
       "        [ 4.2483e-02,  2.8597e-03, -1.5757e-02,  1.0023e-01, -2.2021e-01,\n",
       "          9.1883e-01],\n",
       "        [ 5.5908e-01,  2.1048e-02,  5.1323e-01,  3.3319e+00, -9.6030e-02,\n",
       "          4.8387e-01],\n",
       "        [ 1.7957e+00,  1.4980e+00, -1.3496e+00,  2.6398e+00, -2.5847e-02,\n",
       "          2.1642e+00],\n",
       "        [ 2.6989e-01, -1.7579e-01,  2.8223e-02,  2.3053e-01, -5.1885e-02,\n",
       "          1.7497e-01],\n",
       "        [ 1.7255e-01,  7.1177e-02,  1.0070e-01,  1.6224e-01,  9.2672e-02,\n",
       "          3.1977e-01],\n",
       "        [ 3.7494e-01, -1.6606e-01, -2.7573e-01,  7.4979e-01,  7.7136e-01,\n",
       "          1.6675e+00],\n",
       "        [ 3.0745e+00, -2.5342e-01,  1.6709e-01,  1.8693e+00, -9.1323e-02,\n",
       "          2.0306e-01],\n",
       "        [ 4.4830e-01,  3.5491e-01, -4.6944e-01,  5.8318e-01, -8.5936e-01,\n",
       "          1.4792e+00],\n",
       "        [ 7.2826e-02,  5.4575e-02,  5.0094e-02,  4.4517e-02,  4.1881e-02,\n",
       "          4.0622e-02],\n",
       "        [ 2.8897e-01,  2.0659e-01,  1.2637e-01,  5.2374e-01,  1.8319e-01,\n",
       "          1.8363e-01],\n",
       "        [ 1.5812e+00, -7.6355e-02,  1.0390e-01,  7.3215e-01,  4.2558e-02,\n",
       "          1.8134e+00],\n",
       "        [ 1.4685e+00, -5.7844e-01,  1.6591e+00,  4.7394e-01, -7.1235e-01,\n",
       "          4.1472e+00],\n",
       "        [ 8.9161e-01, -3.4851e-01, -5.5249e-01,  7.4721e-01, -2.2759e-02,\n",
       "          1.1609e+00],\n",
       "        [ 1.7978e-01, -7.5672e-02,  4.3681e-02,  7.2594e-02, -1.1812e-03,\n",
       "          1.7153e-01],\n",
       "        [ 1.2312e+00,  2.0925e-01, -2.7169e-01,  1.1908e+00,  5.4838e-01,\n",
       "          9.7020e-01],\n",
       "        [ 1.5582e+00,  1.2357e+00, -8.8295e-01,  1.2091e+00, -9.6638e-01,\n",
       "          9.7608e-01],\n",
       "        [ 6.3763e-01, -6.6412e-01,  6.3711e-01,  8.8525e-01, -7.7291e-01,\n",
       "          8.3736e-01],\n",
       "        [ 5.0027e-01,  6.0770e-02, -2.3786e-01,  2.3889e-01, -1.7678e-02,\n",
       "          1.0585e+00],\n",
       "        [ 1.8557e-01,  4.8905e-02, -1.8335e-01,  3.8776e-01,  9.8525e-02,\n",
       "          3.1752e-01],\n",
       "        [ 4.4698e+00, -7.5661e-01,  3.3936e+00,  2.9471e-01, -7.8108e-01,\n",
       "          2.8514e+00],\n",
       "        [ 3.4637e-01, -5.9452e-01, -8.4638e-01,  1.3786e+00,  1.2015e+00,\n",
       "          3.6149e+00],\n",
       "        [ 1.6434e-01,  1.1937e-02, -5.0356e-02,  6.3552e-02,  1.2216e-01,\n",
       "          5.4459e-01],\n",
       "        [ 1.1098e+00,  2.4738e-01, -1.9588e-01,  8.8267e-01, -1.3029e-01,\n",
       "          7.4140e-01],\n",
       "        [ 2.7633e-01,  7.4971e-02,  9.5090e-02,  4.3420e-01, -3.6570e-02,\n",
       "          3.6087e-01],\n",
       "        [ 1.9197e+00, -6.3687e-02,  1.8846e-01,  6.2874e-01, -1.9969e-01,\n",
       "          1.5297e+00],\n",
       "        [ 1.2240e+00,  2.8327e-01,  5.6362e-01,  9.3877e-02,  1.3964e-01,\n",
       "          2.6345e-01],\n",
       "        [ 7.8717e-03, -1.0366e-02,  2.5663e-02,  3.8062e-02,  3.0079e-02,\n",
       "          2.8587e-01],\n",
       "        [ 3.2477e-01, -3.4448e-01,  1.4903e-01,  3.6701e-01, -1.5843e-01,\n",
       "          7.1921e-02],\n",
       "        [ 1.3915e-01,  2.9870e-01,  6.5046e-02,  2.1449e+00, -2.7883e-01,\n",
       "          1.2535e+00],\n",
       "        [ 1.4794e+00,  3.9847e-01,  1.2505e+00,  2.9806e+00, -5.6941e-01,\n",
       "          1.5697e+00],\n",
       "        [ 1.1712e+00,  5.2392e-01, -8.4903e-01,  1.3355e+00, -1.1258e+00,\n",
       "          2.6131e+00],\n",
       "        [ 1.8985e-01,  7.3167e-02, -3.5252e-01,  1.1995e+00,  3.0922e-01,\n",
       "          8.3458e-01],\n",
       "        [ 9.0486e-01, -1.1268e+00,  4.5745e-01,  3.0728e+00, -1.2073e+00,\n",
       "          5.0882e-01],\n",
       "        [ 3.9405e-01,  1.9292e-01, -2.0061e-02,  7.9034e-01, -9.1554e-02,\n",
       "          5.1354e-01],\n",
       "        [ 8.2066e-01, -3.4708e-02,  7.4828e-02,  1.0390e-01, -1.3581e-01,\n",
       "          5.4316e-01],\n",
       "        [ 1.2597e+00,  3.8192e-01, -1.7421e-01,  3.6064e+00,  1.4130e-01,\n",
       "          1.1437e+00],\n",
       "        [ 4.1940e-01, -2.2637e-01,  1.0549e-01,  4.4104e-01, -2.2551e-02,\n",
       "          5.9090e-01],\n",
       "        [ 1.6615e-01, -4.3458e-02,  2.4779e-03,  1.3393e-01,  1.0971e-01,\n",
       "          1.1984e-01],\n",
       "        [ 6.8505e-01,  3.9032e-02,  8.2136e-01,  1.1164e-01,  7.9033e-02,\n",
       "          1.0309e+00],\n",
       "        [ 9.7985e-01,  1.0483e-01,  3.5624e-02,  9.8663e-01,  1.1624e-01,\n",
       "          9.0966e-01],\n",
       "        [ 6.2976e-01,  7.9327e-03, -1.9557e-01,  5.0317e-01,  3.4883e-02,\n",
       "          6.6110e-01],\n",
       "        [ 8.2131e-01, -1.8380e-01,  1.0214e+00,  1.8526e-01, -2.7048e-01,\n",
       "          1.5632e+00],\n",
       "        [ 7.2278e-01, -1.6333e-01, -1.3924e-01,  8.4758e-01, -4.1647e-02,\n",
       "          4.4960e-01],\n",
       "        [ 3.9492e-01, -9.1082e-01, -1.1501e-01,  5.2852e+00,  7.6687e-01,\n",
       "          1.0595e+00],\n",
       "        [ 2.2519e-01, -3.8323e-01, -4.2196e-02,  7.5849e-01,  3.6983e-02,\n",
       "          6.6634e-01],\n",
       "        [ 6.3487e-01, -4.3356e-01,  1.7075e-01,  3.5476e-01, -1.5685e-01,\n",
       "          8.5754e-02],\n",
       "        [ 2.1658e-01,  4.4312e-01,  2.6517e-01,  1.5781e+00,  1.5387e+00,\n",
       "          1.9200e+00],\n",
       "        [ 4.0465e-01, -6.7163e-02,  5.5971e-03,  4.5266e-02, -2.8547e-02,\n",
       "          4.1930e-01],\n",
       "        [ 2.3421e+00,  1.0467e+00, -2.2860e-01,  4.7064e-01, -1.0075e-01,\n",
       "          2.3230e-02],\n",
       "        [ 1.4877e+00, -1.5977e-01, -2.2044e+00,  3.9387e-01,  3.4074e-01,\n",
       "          3.2987e+00],\n",
       "        [ 1.4491e-01, -2.4866e-01, -2.0576e-01,  8.7428e-01,  3.1844e-02,\n",
       "          5.5528e-01],\n",
       "        [ 9.2709e-01, -8.3358e-01, -4.2425e-01,  1.1706e+00,  2.2985e-01,\n",
       "          9.8861e-01],\n",
       "        [ 1.0314e+00,  3.1093e-01, -9.8637e-01,  3.2971e-01, -4.3640e-01,\n",
       "          1.6326e+00],\n",
       "        [ 7.2529e-01,  8.9302e-01,  5.9833e-01,  2.3235e+00,  1.3281e+00,\n",
       "          1.2336e+00],\n",
       "        [ 2.0167e+00, -9.9732e-02,  9.6517e-01,  1.5974e+00,  1.2188e+00,\n",
       "          4.1497e+00],\n",
       "        [ 2.2665e-01,  2.6114e-01,  1.5264e-01,  3.3124e-01,  1.9497e-01,\n",
       "          8.3089e-01],\n",
       "        [ 9.0375e-01,  2.0873e-01,  9.3921e-01,  8.8698e-01,  6.7069e-01,\n",
       "          1.8825e+00],\n",
       "        [ 2.3943e-03, -3.2922e-02,  9.7481e-03,  4.5982e-01, -1.5296e-01,\n",
       "          1.8111e-01],\n",
       "        [ 4.3115e-01, -3.6095e-01,  1.1846e-01,  8.9664e-01, -9.1131e-02,\n",
       "          7.5446e-01],\n",
       "        [ 9.1347e-01,  4.7816e-01,  2.7874e-02,  1.1029e+00,  1.7096e-01,\n",
       "          9.5119e-01],\n",
       "        [ 1.3755e-03, -2.2155e-03,  8.0785e-04,  9.9508e-03, -5.0369e-03,\n",
       "          2.7337e-03],\n",
       "        [ 3.0868e+00,  6.4699e-01, -3.7078e-01,  2.4973e-01,  2.6123e-02,\n",
       "          1.6790e-01],\n",
       "        [ 2.5342e+00, -1.0426e+00,  1.4090e-02,  6.6734e+00,  1.8058e+00,\n",
       "          2.4420e+00],\n",
       "        [ 2.8726e+00,  2.9447e-01, -1.6555e-01,  3.1079e+00,  2.8552e-01,\n",
       "          3.7217e-01],\n",
       "        [ 5.0560e-01, -6.5770e-02,  4.2842e-01,  7.3234e-01,  1.6393e-01,\n",
       "          5.0944e-01],\n",
       "        [ 3.9145e+00, -2.3138e+00, -6.1574e-02,  1.4417e+00,  5.1465e-01,\n",
       "          3.7904e+00],\n",
       "        [ 1.4465e+00, -8.3734e-02,  1.1555e-01,  1.5303e+00,  2.2689e-01,\n",
       "          7.2954e-01],\n",
       "        [ 4.0369e-02, -5.5117e-02,  6.9654e-03,  1.0595e-01,  5.6310e-02,\n",
       "          3.4355e-01],\n",
       "        [ 1.1054e+00, -2.6134e-01, -1.7195e-01,  8.9518e-01,  3.5178e-02,\n",
       "          8.6595e-01],\n",
       "        [ 5.0309e-01, -1.5485e-01, -2.6982e-01,  3.4894e-01,  2.7419e-01,\n",
       "          7.6624e-01],\n",
       "        [ 2.6481e-02, -1.7053e-01, -6.6984e-02,  3.1262e+00,  1.3796e+00,\n",
       "          6.6228e-01],\n",
       "        [ 6.1670e-01, -2.0974e-01,  3.7150e-01,  2.5310e-01, -1.1983e-01,\n",
       "          2.3926e-01],\n",
       "        [ 8.4453e-01, -2.0493e-01, -1.2746e+00,  8.3147e-02,  4.8470e-01,\n",
       "          2.8690e+00],\n",
       "        [ 7.6453e-01, -6.0644e-02, -5.9524e-01,  1.5761e+00,  4.5043e-02,\n",
       "          1.2710e+00],\n",
       "        [ 7.3607e-01, -1.2183e+00, -1.7590e-01,  2.2012e+00,  2.2924e-01,\n",
       "          1.1416e-01],\n",
       "        [ 1.0104e+00,  1.1920e-01, -2.2171e-03,  6.0444e-01, -3.1800e-01,\n",
       "          5.6408e-01],\n",
       "        [ 1.3436e+00,  8.1507e-01,  3.6285e-01,  9.2853e-01,  2.8099e-01,\n",
       "          4.2323e-01],\n",
       "        [ 2.2472e+00, -1.4073e-01, -1.2874e-01,  1.6732e+00,  8.2597e-02,\n",
       "          1.4687e+00],\n",
       "        [ 1.7681e+00,  5.1004e-01, -2.3745e-01,  2.6476e-01, -1.8283e-01,\n",
       "          1.9601e+00],\n",
       "        [ 3.8915e-01,  4.8277e-02, -1.3976e-01,  3.6052e-01,  9.8285e-02,\n",
       "          2.3778e-01],\n",
       "        [ 6.5686e-01, -2.8181e-01,  4.1011e-02,  8.9724e-01, -4.0522e-02,\n",
       "          1.0840e-01],\n",
       "        [ 1.1787e+00,  5.0462e-01,  1.6494e-01,  1.1106e+00, -8.2242e-02,\n",
       "          1.4639e+00],\n",
       "        [ 4.4607e+00, -1.3748e+00, -8.3198e-01,  2.3696e+00, -1.7461e+00,\n",
       "          3.0826e+00],\n",
       "        [ 2.1147e-01, -2.2716e-01, -2.3246e-01,  6.8710e-01,  6.6211e-01,\n",
       "          6.9279e-01],\n",
       "        [ 9.0219e-01, -1.1315e+00, -4.4276e-03,  2.2054e+00,  2.6792e-02,\n",
       "          1.4638e-01],\n",
       "        [ 3.4773e-01,  2.2153e-01,  2.6320e-01,  7.6768e-01, -1.1437e-01,\n",
       "          7.3577e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1150, -0.9386, -1.2061],\n",
       "        [ 1.2101, -1.3982, -1.2553],\n",
       "        [-0.9554,  1.1580, -0.7895],\n",
       "        [ 0.6118,  0.7821, -1.0802],\n",
       "        [-0.9496, -1.0083,  0.4498],\n",
       "        [ 0.6847, -0.9190,  0.4641],\n",
       "        [-0.7937,  0.9383,  0.4655],\n",
       "        [ 0.8571,  0.4280,  0.6931]], device='cuda:0')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6002,  0.0053,  0.4492,  0.5337,  0.0951,  0.9660],\n",
       "        [ 1.3554,  0.3313,  0.2212,  1.4141,  0.0587,  0.9869],\n",
       "        [ 0.6641, -0.0925, -0.1752,  1.1153,  0.0428,  0.5854],\n",
       "        [ 1.9483,  0.2515,  0.2096,  2.1152, -0.2107,  1.5738],\n",
       "        [ 0.7485,  0.0105, -0.1144,  1.3327,  0.3460,  1.3714],\n",
       "        [ 1.2583,  0.0675, -0.3408,  1.1805,  0.0855,  1.5241],\n",
       "        [ 1.0597,  0.0228, -0.0241,  1.1374, -0.0286,  1.1231],\n",
       "        [ 1.8036, -0.3376,  0.1089,  1.7728,  0.0638,  2.1481]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6002, 0.0053, 0.4492, 0.5337, 0.0951, 0.9660], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sigma = torch.zeros(6, 1).cuda()\n",
    "\n",
    "group_id = 0\n",
    "grouped_xyzs = xyzs[(unique_per_col_gaussian_node_assignments == group_id)[:, 0]]\n",
    "grouped_sigmas = sigmas[(unique_per_col_gaussian_node_assignments == group_id)[:, 0]]\n",
    "grouped_weights = weights[(unique_per_col_gaussian_node_assignments == group_id)[:, 0]]\n",
    "for i in range(grouped_xyzs.shape[0]):\n",
    "    sigma[0] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 0] + (grouped_xyzs[i] - new_means[group_id])[0] * (grouped_xyzs[i] - new_means[group_id])[0])\n",
    "    sigma[1] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 1] + (grouped_xyzs[i] - new_means[group_id])[0] * (grouped_xyzs[i] - new_means[group_id])[1])\n",
    "    sigma[2] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 2] + (grouped_xyzs[i] - new_means[group_id])[0] * (grouped_xyzs[i] - new_means[group_id])[2])\n",
    "    sigma[3] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 3] + (grouped_xyzs[i] - new_means[group_id])[1] * (grouped_xyzs[i] - new_means[group_id])[1])\n",
    "    sigma[4] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 4] + (grouped_xyzs[i] - new_means[group_id])[1] * (grouped_xyzs[i] - new_means[group_id])[2])\n",
    "    sigma[5] += (grouped_weights[i] / grouped_weights.sum()) * \\\n",
    "        (grouped_sigmas[i, 5] + (grouped_xyzs[i] - new_means[group_id])[2] * (grouped_xyzs[i] - new_means[group_id])[2])\n",
    "\n",
    "print(sigma.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2, 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
