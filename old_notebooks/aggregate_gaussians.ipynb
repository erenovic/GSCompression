{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin_scratch/GSCodec/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec/notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import load, load_inline, is_ninja_available\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "os.environ['TORCH_USE_CUDA_DSA']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(is_ninja_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = r'''\n",
    "#include <torch/types.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#include <vector_types.h>\n",
    "#include <device_launch_parameters.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "\n",
    "\n",
    "__global__ void aggregate_gaussians_forward(\n",
    "    float *xyzs, \n",
    "    float *shs, \n",
    "    float *covariances, \n",
    "    float *opacities, \n",
    "    float *weights,\n",
    "    int *node_ids, \n",
    "    float *node_locations, \n",
    "    float *node_harmonics, \n",
    "    float *node_covariances, \n",
    "    float *node_opacities,\n",
    "    float *node_total_weights,\n",
    "    int N,\n",
    "    int octree_depth) \n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= N) return;\n",
    "\n",
    "    int node_idx;\n",
    "    float weight = weights[idx];\n",
    "    \n",
    "    for (int j = 0; j < octree_depth; j++) {\n",
    "        node_idx = node_ids[idx * octree_depth + j];\n",
    "        if (node_idx == -1) continue; // Skip empty slots\n",
    "\n",
    "        atomicAdd(&node_opacities[node_idx], weight * opacities[idx]);\n",
    "        atomicAdd(&node_total_weights[node_idx], weight);\n",
    "\n",
    "        for (int k = 0; k < 3; k++) {\n",
    "            atomicAdd(&node_locations[node_idx * 3 + k], weight * xyzs[idx * 3 + k]);\n",
    "        }\n",
    "\n",
    "        for (int k = 0; k < 48; k++) {\n",
    "            atomicAdd(&node_harmonics[node_idx * 48 + k], weight * shs[idx * 48 + k]);\n",
    "        }\n",
    "\n",
    "        for (int k = 0; k < 9; k++) {\n",
    "            atomicAdd(&node_covariances[node_idx * 9 + k], weight * covariances[idx * 9 + k]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void aggregate_gaussians_backward(\n",
    "    float *grad_xyzs, \n",
    "    float *grad_shs, \n",
    "    float *grad_covariances, \n",
    "    float *grad_opacities,\n",
    "    float *grad_weights,\n",
    "    float *xyzs, \n",
    "    float *shs, \n",
    "    float *covariances, \n",
    "    float *opacities, \n",
    "    float *weights,\n",
    "    int *node_ids, \n",
    "    float *node_total_weights,\n",
    "    float *node_grad_locations, \n",
    "    float *node_grad_harmonics, \n",
    "    float *node_grad_covariances, \n",
    "    float *node_grad_opacities,\n",
    "    int N,\n",
    "    int octree_depth) \n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= N) return;\n",
    "\n",
    "    int node_idx;\n",
    "    float weight = weights[idx];\n",
    "    float weight_grad = 0.0f;\n",
    "\n",
    "    for (int j = 0; j < octree_depth; j++) {\n",
    "        node_idx = node_ids[idx * octree_depth + j];\n",
    "        if (node_idx == -1) continue; // Skip empty slots\n",
    "\n",
    "        float normalized_weight = weight / (node_total_weights[node_idx] + 1e-8); // Avoid division by zero\n",
    "        \n",
    "        atomicAdd(&grad_opacities[idx], normalized_weight * node_grad_opacities[node_idx]);\n",
    "        weight_grad += opacities[idx] * node_grad_opacities[node_idx];\n",
    "        \n",
    "        for (int k = 0; k < 3; k++) {\n",
    "            atomicAdd(&grad_xyzs[idx * 3 + k], normalized_weight * node_grad_locations[node_idx * 3 + k]);\n",
    "            weight_grad += xyzs[idx * 3 + k] * node_grad_locations[node_idx * 3 + k];\n",
    "        }\n",
    "        \n",
    "        for (int k = 0; k < 48; k++) {\n",
    "            atomicAdd(&grad_shs[idx * 48 + k], normalized_weight * node_grad_harmonics[node_idx * 48 + k]);\n",
    "            weight_grad += shs[idx * 48 + k] * node_grad_harmonics[node_idx * 48 + k];\n",
    "        }\n",
    "\n",
    "        for (int k = 0; k < 9; k++) {\n",
    "            atomicAdd(&grad_covariances[idx * 9 + k], normalized_weight * node_grad_covariances[node_idx * 9 + k]);\n",
    "            weight_grad += covariances[idx * 9 + k] * node_grad_covariances[node_idx * 9 + k];\n",
    "        }\n",
    "    }\n",
    "    atomicAdd(&grad_weights[idx], weight_grad);\n",
    "}\n",
    "\n",
    "\n",
    "// Host function to invoke the forward kernel\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor> \n",
    "aggregate_gaussians_forward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const int num_unique_nodes,\n",
    "    const int octree_depth) \n",
    "{\n",
    "    CHECK_INPUT(xyzs);\n",
    "    CHECK_INPUT(shs);\n",
    "    CHECK_INPUT(covariances);\n",
    "    CHECK_INPUT(opacities);\n",
    "    CHECK_INPUT(weights);\n",
    "    CHECK_INPUT(node_ids);\n",
    "\n",
    "    int N = xyzs.size(0);\n",
    "    int num_nodes = node_ids.size(0);\n",
    "\n",
    "    torch::Tensor node_locations = torch::zeros({num_unique_nodes, 3}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_harmonics = torch::zeros({num_unique_nodes, 48}, torch::CUDA(torch::kFloat)); \n",
    "    torch::Tensor node_covariances = torch::zeros({num_unique_nodes, 9}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_opacities = torch::zeros({num_unique_nodes}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_total_weights = torch::zeros({num_unique_nodes}, torch::CUDA(torch::kFloat));\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    aggregate_gaussians_forward<<<blocks, threads>>>(\n",
    "        xyzs.data_ptr<float>(), \n",
    "        shs.data_ptr<float>(), \n",
    "        covariances.data_ptr<float>(), \n",
    "        opacities.data_ptr<float>(), \n",
    "        weights.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(), \n",
    "        node_locations.data_ptr<float>(), \n",
    "        node_harmonics.data_ptr<float>(), \n",
    "        node_covariances.data_ptr<float>(), \n",
    "        node_opacities.data_ptr<float>(),\n",
    "        node_total_weights.data_ptr<float>(),\n",
    "        N,\n",
    "        octree_depth\n",
    "    );\n",
    "\n",
    "    return std::make_tuple(\n",
    "        node_locations, node_harmonics, node_covariances, \n",
    "        node_opacities, node_total_weights);\n",
    "}\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians_backward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const torch::Tensor node_total_weights,\n",
    "    const torch::Tensor node_grad_locations, \n",
    "    const torch::Tensor node_grad_harmonics, \n",
    "    const torch::Tensor node_grad_covariances, \n",
    "    const torch::Tensor node_grad_opacities,\n",
    "    const int octree_depth) \n",
    "{\n",
    "    CHECK_INPUT(xyzs);\n",
    "    CHECK_INPUT(shs);\n",
    "    CHECK_INPUT(covariances);\n",
    "    CHECK_INPUT(opacities);\n",
    "    CHECK_INPUT(weights);\n",
    "    CHECK_INPUT(node_ids);\n",
    "    CHECK_INPUT(node_grad_locations);\n",
    "    CHECK_INPUT(node_grad_harmonics);\n",
    "    CHECK_INPUT(node_grad_covariances);\n",
    "    CHECK_INPUT(node_grad_opacities);\n",
    "    CHECK_INPUT(node_total_weights);\n",
    "\n",
    "    int N = xyzs.size(0);\n",
    "\n",
    "    auto grad_xyzs = torch::zeros_like(xyzs);\n",
    "    auto grad_shs = torch::zeros_like(shs);\n",
    "    auto grad_covariances = torch::zeros_like(covariances);\n",
    "    auto grad_opacities = torch::zeros_like(opacities);\n",
    "    auto grad_weights = torch::zeros_like(weights);\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    aggregate_gaussians_backward<<<blocks, threads>>>(\n",
    "        grad_xyzs.data_ptr<float>(), \n",
    "        grad_shs.data_ptr<float>(), \n",
    "        grad_covariances.data_ptr<float>(), \n",
    "        grad_opacities.data_ptr<float>(),\n",
    "        grad_weights.data_ptr<float>(),\n",
    "        xyzs.data_ptr<float>(), \n",
    "        shs.data_ptr<float>(), \n",
    "        covariances.data_ptr<float>(), \n",
    "        opacities.data_ptr<float>(), \n",
    "        weights.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(),\n",
    "        node_total_weights.data_ptr<float>(),\n",
    "        node_grad_locations.data_ptr<float>(), \n",
    "        node_grad_harmonics.data_ptr<float>(), \n",
    "        node_grad_covariances.data_ptr<float>(), \n",
    "        node_grad_opacities.data_ptr<float>(),\n",
    "        N,\n",
    "        octree_depth\n",
    "    );\n",
    "\n",
    "    return std::make_tuple(grad_xyzs, grad_shs, grad_covariances, grad_opacities, grad_weights);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_src = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <cstdio>\n",
    "#include <tuple>\n",
    "#include <string>\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor> \n",
    "aggregate_gaussians_forward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities,\n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const int num_unique_nodes,\n",
    "    const int octree_depth);\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians_backward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const torch::Tensor node_total_weights,\n",
    "    const torch::Tensor node_grad_locations, \n",
    "    const torch::Tensor node_grad_harmonics, \n",
    "    const torch::Tensor node_grad_covariances, \n",
    "    const torch::Tensor node_grad_opacities,\n",
    "    const int octree_depth);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file aggregate/build.ninja...\n",
      "Building extension module my_cuda_extension...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=my_cuda_extension -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/TH -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/THC -isystem /include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /scratch_net/biwidl214/ecetin_scratch/GSCodec/notebooks/aggregate/main.cpp -o main.o \n",
      "[2/3] /bin/nvcc  -DTORCH_EXTENSION_NAME=my_cuda_extension -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/TH -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/include/THC -isystem /include -isystem /scratch_net/biwidl214/ecetin/conda_envs/gscodec/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -std=c++17 -c /scratch_net/biwidl214/ecetin_scratch/GSCodec/notebooks/aggregate/cuda.cu -o cuda.cuda.o \n",
      "[3/3] c++ main.o cuda.cuda.o -shared -L/scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/lib64 -lcudart -o my_cuda_extension.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my_cuda_extension...\n"
     ]
    }
   ],
   "source": [
    "module = load_inline(\n",
    "    cuda_sources=[cuda_src], cpp_sources=[cpp_src], \n",
    "    functions=[\"aggregate_gaussians_forward_cuda\", \"aggregate_gaussians_backward_cuda\"],\n",
    "    build_directory=\"aggregate\",\n",
    "    extra_cuda_cflags=[],\n",
    "    verbose=True, name=\"my_cuda_extension\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin_scratch/GSCodec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.splatting.hierarchical_model.hierarhical_utils import generate_octree\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200000\n",
    "points = torch.rand(N, 3).cuda()\n",
    "covs = torch.rand(N, 3, 3).cuda()\n",
    "shs = torch.rand(N, 16, 3).cuda()\n",
    "opacities = torch.rand(N).cuda()\n",
    "weights = torch.rand(N).cuda()\n",
    "\n",
    "box_min = torch.min(points, dim=0)[0]\n",
    "box_max = torch.max(points, dim=0)[0]\n",
    "box_d = box_max - box_min\n",
    "box_min = box_min - 0.1 * box_d\n",
    "box_max = box_max + 0.1 * box_d\n",
    "max_depth = 10\n",
    "init_level=1\n",
    "\n",
    "# point_level_bboxes, point_node_assignment = generate_octree(\n",
    "#     points, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     3,     30,    241,  ..., 395293, 593547, 784532],\n",
      "        [     0,      4,     33,  ..., 216635, 406623, 604848],\n",
      "        [     5,     43,    344,  ..., 441626, 640065, 826282],\n",
      "        ...,\n",
      "        [     1,      9,     76,  ..., 321810, 519622, 717667],\n",
      "        [     5,     42,    338,  ..., 437264, 635704, 822385],\n",
      "        [     7,     62,    497,  ..., 512255, 710483, 886554]],\n",
      "       device='cuda:0')\n",
      "889655\n"
     ]
    }
   ],
   "source": [
    "# unique_nodes, inverse_indices = torch.unique(\n",
    "#     point_node_assignment, return_inverse=True)\n",
    "# node_ids = torch.arange(0, unique_nodes.size(0), device=point_node_assignment.device)\n",
    "# node_ids = node_ids[inverse_indices]\n",
    "# num_unique_nodes = unique_nodes.size(0)\n",
    "node_ids = torch.load(\"notebooks/node_ids_200000.pt\").cuda()\n",
    "print(node_ids)\n",
    "num_unique_nodes = torch.unique(node_ids).size(0)\n",
    "print(num_unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_xyzs, node_shs, node_covs, node_opacities, node_weights = \\\n",
    "    module.aggregate_gaussians_forward_cuda(\n",
    "        points, shs, covs, opacities, weights, node_ids.type(torch.int32), \n",
    "        num_unique_nodes, max_depth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4989, 0.5012, 0.5012],\n",
       "        [0.4968, 0.4992, 0.4993],\n",
       "        [0.4996, 0.4994, 0.4995],\n",
       "        ...,\n",
       "        [0.1703, 0.2481, 0.5655],\n",
       "        [0.4204, 0.7861, 0.0779],\n",
       "        [0.4590, 0.7854, 0.2827]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_xyzs / node_weights[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6961e+03, 6.7276e+03, 6.7276e+03],\n",
       "        [6.8676e+03, 6.9005e+03, 6.9017e+03],\n",
       "        [6.8560e+03, 6.8533e+03, 6.8550e+03],\n",
       "        ...,\n",
       "        [1.5648e-01, 2.2798e-01, 5.1960e-01],\n",
       "        [2.6751e-01, 5.0026e-01, 4.9569e-02],\n",
       "        [4.5149e-01, 7.7249e-01, 2.7810e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_xyzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2781, 0.7842, 0.2118],\n",
       "        [0.3426, 0.9232, 0.5663],\n",
       "        [0.5632, 0.0404, 0.2173],\n",
       "        ...,\n",
       "        [0.2359, 0.8826, 0.4234],\n",
       "        [0.0728, 0.8092, 0.9179],\n",
       "        [0.6692, 0.9160, 0.6547]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(node_ids, \"notebooks/node_ids_200000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_gaussians(self, weights, gaussian_node_assignments, num_unique_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "#include <torch/types.h>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#include <vector_types.h>\n",
    "#include <device_launch_parameters.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "__global__ void aggregate_gaussians_forward(\n",
    "    float *xyzs, \n",
    "    float *shs, \n",
    "    float *covariances, \n",
    "    float *opacities, \n",
    "    float *weights,\n",
    "    int *node_ids, \n",
    "    float *node_locations, \n",
    "    float *node_harmonics, \n",
    "    float *node_covariances, \n",
    "    float *node_opacities,\n",
    "    float *node_total_weights,\n",
    "    int N) \n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= N) return;\n",
    "\n",
    "    int node_idx;\n",
    "    float weight = weights[idx];\n",
    "    \n",
    "    for (int j = 0; j < 10; j++) {\n",
    "        node_idx = node_ids[idx * 10 + j];\n",
    "        if (node_idx == -1) continue; // Skip empty slots\n",
    "\n",
    "        atomicAdd(&node_opacities[node_idx], weight * opacities[idx]);\n",
    "        atomicAdd(&node_total_weights[node_idx], weight);\n",
    "\n",
    "        for (int k = 0; k < 3; k++) {\n",
    "            atomicAdd(&node_locations[node_idx * 3 + k], weight * xyzs[idx * 3 + k]);\n",
    "        }\n",
    "\n",
    "        for (int k = 0; k < 48; k++) {\n",
    "            atomicAdd(&node_harmonics[node_idx * 48 + k], weight * shs[idx * 48 + k]);\n",
    "        }\n",
    "\n",
    "        // Aggregated all except covariances. Now we will do them\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void aggregate_gaussians_backward(\n",
    "    float *grad_xyzs, \n",
    "    float *grad_shs, \n",
    "    float *grad_covariances, \n",
    "    float *grad_opacities,\n",
    "    float *xyzs, \n",
    "    float *shs, \n",
    "    float *covariances, \n",
    "    float *opacities, \n",
    "    float *weights,\n",
    "    int *node_ids, \n",
    "    float *node_grad_locations, \n",
    "    float *node_grad_harmonics, \n",
    "    float *node_grad_covariances, \n",
    "    float *node_grad_opacities,\n",
    "    float *node_total_weights,\n",
    "    int N) \n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx >= N) return;\n",
    "\n",
    "    int node_idx;\n",
    "    float weight = weights[idx];\n",
    "\n",
    "    for (int j = 0; j < 10; j++) {\n",
    "        node_idx = node_ids[idx * 10 + j];\n",
    "        if (node_idx == -1) continue; // Skip empty slots\n",
    "\n",
    "        float normalized_weight = weight / (node_total_weights[node_idx] + 1e-8); // Avoid division by zero\n",
    "        \n",
    "        atomicAdd(&grad_opacities[idx], normalized_weight * node_grad_opacities[node_idx]);\n",
    "        \n",
    "        for (int k = 0; k < 3; k++) {\n",
    "            atomicAdd(&grad_xyzs[idx * 3 + k], normalized_weight * node_grad_locations[node_idx * 3 + k]);\n",
    "        }\n",
    "        \n",
    "        for (int k = 0; k < 48; k++) {\n",
    "            atomicAdd(&grad_shs[idx * 48 + k], normalized_weight * node_grad_harmonics[node_idx * 48 + k]);\n",
    "        }\n",
    "\n",
    "        for (int k = 0; k < 9; k++) {\n",
    "            atomicAdd(&grad_covariances[idx * 9 + k], normalized_weight * node_grad_covariances[node_idx * 9 + k]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// Host function to invoke the forward kernel\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor> \n",
    "aggregate_gaussians_forward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const int num_unique_nodes) \n",
    "{\n",
    "    CHECK_INPUT(xyzs);\n",
    "    CHECK_INPUT(shs);\n",
    "    CHECK_INPUT(covariances);\n",
    "    CHECK_INPUT(opacities);\n",
    "    CHECK_INPUT(weights);\n",
    "    CHECK_INPUT(node_ids);\n",
    "\n",
    "    int N = xyzs.size(0);\n",
    "    int num_nodes = node_ids.size(0);\n",
    "\n",
    "    torch::Tensor node_locations = torch::zeros({num_unique_nodes, 3}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_harmonics = torch::zeros({num_unique_nodes, 48}, torch::CUDA(torch::kFloat)); \n",
    "    torch::Tensor node_covariances = torch::zeros({num_unique_nodes, 9}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_opacities = torch::zeros({num_unique_nodes}, torch::CUDA(torch::kFloat));\n",
    "    torch::Tensor node_total_weights = torch::zeros({num_unique_nodes}, torch::CUDA(torch::kFloat));\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    aggregate_gaussians_forward<<<blocks, threads>>>(\n",
    "        xyzs.data_ptr<float>(), \n",
    "        shs.data_ptr<float>(), \n",
    "        covariances.data_ptr<float>(), \n",
    "        opacities.data_ptr<float>(), \n",
    "        weights.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(), \n",
    "        node_locations.data_ptr<float>(), \n",
    "        node_harmonics.data_ptr<float>(), \n",
    "        node_covariances.data_ptr<float>(), \n",
    "        node_opacities.data_ptr<float>(),\n",
    "        node_total_weights.data_ptr<float>(),\n",
    "        N\n",
    "    );\n",
    "\n",
    "    aggregate_gaussians_covariances_forward<<<blocks, threads>>>(\n",
    "        xyzs.data_ptr<float>(),\n",
    "        covariances.data_ptr<float>(),\n",
    "        weights.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(),\n",
    "        node covariances.data_ptr<float>());\n",
    "\n",
    "    return std::make_tuple(\n",
    "        node_locations, node_harmonics, node_covariances, \n",
    "        node_opacities, node_total_weights, node_ids);\n",
    "}\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians_backward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const torch::Tensor node_grad_locations, \n",
    "    const torch::Tensor node_grad_harmonics, \n",
    "    const torch::Tensor node_grad_covariances, \n",
    "    const torch::Tensor node_grad_opacities,\n",
    "    const torch::Tensor node_total_weights) \n",
    "{\n",
    "    CHECK_INPUT(xyzs);\n",
    "    CHECK_INPUT(shs);\n",
    "    CHECK_INPUT(covariances);\n",
    "    CHECK_INPUT(opacities);\n",
    "    CHECK_INPUT(weights);\n",
    "    CHECK_INPUT(node_ids);\n",
    "    CHECK_INPUT(node_grad_locations);\n",
    "    CHECK_INPUT(node_grad_harmonics);\n",
    "    CHECK_INPUT(node_grad_covariances);\n",
    "    CHECK_INPUT(node_grad_opacities);\n",
    "    CHECK_INPUT(node_total_weights);\n",
    "\n",
    "    int N = xyzs.size(0);\n",
    "\n",
    "    auto grad_xyzs = torch::zeros_like(xyzs);\n",
    "    auto grad_shs = torch::zeros_like(shs);\n",
    "    auto grad_covariances = torch::zeros_like(covariances);\n",
    "    auto grad_opacities = torch::zeros_like(opacities);\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    aggregate_gaussians_backward<<<blocks, threads>>>(\n",
    "        grad_xyzs.data_ptr<float>(), \n",
    "        grad_shs.data_ptr<float>(), \n",
    "        grad_covariances.data_ptr<float>(), \n",
    "        grad_opacities.data_ptr<float>(),\n",
    "        xyzs.data_ptr<float>(), \n",
    "        shs.data_ptr<float>(), \n",
    "        covariances.data_ptr<float>(), \n",
    "        opacities.data_ptr<float>(), \n",
    "        weights.data_ptr<float>(),\n",
    "        node_ids.data_ptr<int>(),\n",
    "        node_grad_locations.data_ptr<float>(), \n",
    "        node_grad_harmonics.data_ptr<float>(), \n",
    "        node_grad_covariances.data_ptr<float>(), \n",
    "        node_grad_opacities.data_ptr<float>(),\n",
    "        node_total_weights.data_ptr<float>(),\n",
    "        N\n",
    "    );\n",
    "\n",
    "    return std::make_tuple(grad_xyzs, grad_shs, grad_covariances, grad_opacities);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_src = r'''\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor> \n",
    "aggregate_gaussians_forward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const int num_unique_nodes);\n",
    "\n",
    "std::tuple<torch::Tensor, torch::Tensor, torch::Tensor, torch::Tensor>\n",
    "aggregate_gaussians_backward_cuda(\n",
    "    const torch::Tensor xyzs, \n",
    "    const torch::Tensor shs, \n",
    "    const torch::Tensor covariances, \n",
    "    const torch::Tensor opacities, \n",
    "    const torch::Tensor weights,\n",
    "    const torch::Tensor node_ids,\n",
    "    const torch::Tensor node_grad_locations, \n",
    "    const torch::Tensor node_grad_harmonics, \n",
    "    const torch::Tensor node_grad_covariances, \n",
    "    const torch::Tensor node_grad_opacities,\n",
    "    const torch::Tensor node_total_weights);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No modifications detected for re-loaded extension module my_cuda_extension_v2, skipping build step...\n",
      "Loading extension module my_cuda_extension_v2...\n"
     ]
    }
   ],
   "source": [
    "module = load_inline(\n",
    "    cuda_sources=[cuda_src], cpp_sources=[cpp_src], \n",
    "    functions=[\"aggregate_gaussians_forward_cuda\", \"aggregate_gaussians_backward_cuda\"],\n",
    "    build_directory=\"aggregate\",\n",
    "    extra_cuda_cflags=[],\n",
    "    verbose=True, name=\"my_cuda_extension\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin_scratch/GSCodec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_net/biwidl214/ecetin/conda_envs/gscodec/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch_net/biwidl214/ecetin_scratch/GSCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ecetin/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ecetin/.cache/torch_extensions/py310_cu118/pointops/build.ninja...\n",
      "Building extension module pointops...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module pointops...\n",
      "Using /home/ecetin/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ecetin/.cache/torch_extensions/py310_cu118/octree_generation/build.ninja...\n",
      "Building extension module octree_generation...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module octree_generation...\n"
     ]
    }
   ],
   "source": [
    "from models.splatting.hierarchical_model.hierarhical_utils import generate_octree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "points = torch.rand(N, 3).cuda()\n",
    "covs = torch.rand(N, 3, 3).cuda()\n",
    "shs = torch.rand(N, 16, 3).cuda()\n",
    "opacities = torch.rand(N).cuda()\n",
    "weights = torch.rand(N).cuda()\n",
    "\n",
    "box_min = torch.min(points, dim=0)[0]\n",
    "box_max = torch.max(points, dim=0)[0]\n",
    "box_d = box_max - box_min\n",
    "box_min = box_min - 0.1 * box_d\n",
    "box_max = box_max + 0.1 * box_d\n",
    "max_depth = 8\n",
    "init_level=1\n",
    "\n",
    "point_level_bboxes, point_node_assignment = generate_octree(\n",
    "    points, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "print(point_node_assignment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_assignments = point_node_assignment.view(-1).type(torch.int64)\n",
    "\n",
    "unique_nodes, inverse_indices = torch.unique(\n",
    "    flattened_assignments, return_inverse=True, sorted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes, inverse_indices = torch.unique(point_node_assignment, return_inverse=True, sorted=True)\n",
    "# unique_nodes[inverse_indices] == point_node_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_node_ids = torch.arange(0, unique_nodes.size(0), dtype=torch.int32).cuda()\n",
    "# unique_nodes[new_node_ids][inverse_indices] == point_node_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([76])\n"
     ]
    }
   ],
   "source": [
    "print(new_node_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_locations, node_harmonics, node_covariances, \\\n",
    "    node_opacities, node_total_weights, node_ids = module.aggregate_gaussians_forward_cuda(\n",
    "    points, shs, covs, opacities, weights, new_node_ids, unique_nodes.size(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([76, 3])\n",
      "torch.Size([76, 48])\n",
      "torch.Size([76, 9])\n",
      "torch.Size([76])\n",
      "torch.Size([76])\n",
      "torch.Size([76])\n"
     ]
    }
   ],
   "source": [
    "print(node_locations.shape)\n",
    "print(node_harmonics.shape)\n",
    "print(node_covariances.shape)\n",
    "print(node_opacities.shape)\n",
    "print(node_total_weights.shape)\n",
    "print(node_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([43, 48])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
